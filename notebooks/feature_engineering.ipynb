{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff6ceb0-9b28-45fa-86c4-c2a16df4a4fc",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "In this tutorial, we will show you how to use zephyr_ml to create EntitySets, generate label times, and do automated feature engineering. This tutorial assumes you have a folder with the mostly pre-processed data in seperate CSVs. If necessary, please update the steps and paths below.\n",
    "\n",
    "## 1) Create EntitySet\n",
    "zephyr_ml has strict assumptions about the data passed into its `create_pidata_entityset` and `create_scada_entityset` functions. It's the user's responsibility to apply the necessary pre-processing steps to get data into a format acceptable for zephyr_ml. \n",
    "\n",
    "For example, the demo PI data needs to be converted to a tabular format instead of a `tag` `value` format. The `turbine` column also needs too be renamed to `COD_ELEMENT` to match the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f11a97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>turbine</th>\n",
       "      <th>tag</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-02 13:21:01</td>\n",
       "      <td>0</td>\n",
       "      <td>T0.val1</td>\n",
       "      <td>9872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02 13:21:01</td>\n",
       "      <td>0</td>\n",
       "      <td>T0.val2</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-08 13:21:01</td>\n",
       "      <td>0</td>\n",
       "      <td>T0.val1</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-08 13:21:01</td>\n",
       "      <td>0</td>\n",
       "      <td>T0.val2</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  turbine      tag     val\n",
       "0  2022-01-02 13:21:01        0  T0.val1  9872.0\n",
       "1  2022-01-02 13:21:01        0  T0.val2    10.0\n",
       "2  2022-03-08 13:21:01        0  T0.val1   559.0\n",
       "3  2022-03-08 13:21:01        0  T0.val2    -7.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "\n",
    "data_path = 'data'\n",
    "\n",
    "pidata_df = pd.read_csv(path.join(data_path, 'pidata.csv'))\n",
    "pidata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17cd61b9-096b-4359-93eb-b1c63b99e79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tag</th>\n",
       "      <th>time</th>\n",
       "      <th>COD_ELEMENT</th>\n",
       "      <th>val1</th>\n",
       "      <th>val2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-02 13:21:01</td>\n",
       "      <td>0</td>\n",
       "      <td>9872.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-08 13:21:01</td>\n",
       "      <td>0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tag                 time  COD_ELEMENT    val1  val2\n",
       "0    2022-01-02 13:21:01            0  9872.0  10.0\n",
       "1    2022-03-08 13:21:01            0   559.0  -7.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pidata_df['tag'] = pidata_df['tag'].apply(lambda x: '.'.join(x.split('.')[1:]))\n",
    "pidata_df = pd.pivot_table(pidata_df, index=['time', 'turbine'],\n",
    "                            columns=['tag']).droplevel(0, axis=1).reset_index()\n",
    "pidata_df.rename(columns={'turbine': 'COD_ELEMENT'}, inplace=True)\n",
    "pidata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6828251",
   "metadata": {},
   "source": [
    "Once the necessary preprocessing steps have been done, the dataframes can be passed to the respective create EntitySet function. The keys used for the data dictionary are significant, and must match the ones used in this example. Default column names and entity keywork arguments can be overwritten by passing in a dictionary mapping entity names to keyword arguments for adding the dataframe to the EntitySet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bfd56a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: PI data\n",
       "  DataFrames:\n",
       "    turbines [Rows: 1, Columns: 10]\n",
       "    alarms [Rows: 2, Columns: 10]\n",
       "    stoppages [Rows: 2, Columns: 16]\n",
       "    work_orders [Rows: 2, Columns: 20]\n",
       "    notifications [Rows: 2, Columns: 15]\n",
       "    pidata [Rows: 2, Columns: 5]\n",
       "  Relationships:\n",
       "    alarms.COD_ELEMENT -> turbines.COD_ELEMENT\n",
       "    stoppages.COD_ELEMENT -> turbines.COD_ELEMENT\n",
       "    work_orders.COD_ELEMENT -> turbines.COD_ELEMENT\n",
       "    pidata.COD_ELEMENT -> turbines.COD_ELEMENT\n",
       "    notifications.COD_ORDER -> work_orders.COD_ORDER"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zephyr_ml import create_pidata_entityset\n",
    "\n",
    "data = {\n",
    "    'turbines': pd.read_csv(path.join(data_path, 'turbines.csv')),\n",
    "    'alarms': pd.read_csv(path.join(data_path, 'alarms.csv')),\n",
    "    'stoppages': pd.read_csv(path.join(data_path, 'stoppages.csv')),\n",
    "    'work_orders': pd.read_csv(path.join(data_path, 'work_orders.csv')),\n",
    "    'notifications': pd.read_csv(path.join(data_path, 'notifications.csv')),\n",
    "    'pidata': pidata_df\n",
    "}\n",
    "\n",
    "pidata_es = create_pidata_entityset(data)\n",
    "pidata_es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746e7e1",
   "metadata": {},
   "source": [
    "## 2) Generating Labels and Cutoff Times\n",
    "The `DataLabeler` is used to generate labels and label times for an EntitySet. It is instantiated with a labeling function, and labels can be generated by calling the `generate_label_times` method. The list of available labeling functions can be found using `zephyr_ml.labeling.get_labeling_functions()`. Custom labeling functions can also be created, provided they follow the expected format of returning the deserialized dataframe, the actual labeling function to use for the dataslice, and additional metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ee16eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_ELEMENT</th>\n",
       "      <th>time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>45801.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COD_ELEMENT       time    label\n",
       "0            0 2022-01-01  45801.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zephyr_ml import DataLabeler, labeling\n",
    "\n",
    "data_labeler = DataLabeler(labeling.total_power_loss)\n",
    "\n",
    "label_times, _ = data_labeler.generate_label_times(pidata_es)\n",
    "label_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aacf99b",
   "metadata": {},
   "source": [
    "## 3) Feature Engineering with Featuretools\n",
    "Using EntitySets and LabelTimes allows us to easily use Featuretools for automatic feature generation. For example, we can set interesting categorical values in our EntitySet and use them to generate aggregation features grouped by those interesting values. We can also set which primitives we want to use and control which columns and entities those primitives can be applied to. Featuretools can also use label times as cutoff times, ensuring that data after the label times is not used in feature generation. \n",
    "\n",
    "For additonal help using Featuretools, please see the documentation: https://featuretools.alteryx.com/en/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee020300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Feature: TURBINE_PI_ID>,\n",
       " <Feature: TURBINE_LOCAL_ID>,\n",
       " <Feature: TURBINE_SAP_COD>,\n",
       " <Feature: DES_CORE_ELEMENT>,\n",
       " <Feature: SITE>,\n",
       " <Feature: DES_CORE_PLANT>,\n",
       " <Feature: COD_PLANT_SAP>,\n",
       " <Feature: PI_COLLECTOR_SITE_NAME>,\n",
       " <Feature: PI_LOCAL_SITE_NAME>,\n",
       " <Feature: COUNT(alarms)>,\n",
       " <Feature: MAX(alarms.IND_DURATION)>,\n",
       " <Feature: MIN(alarms.IND_DURATION)>,\n",
       " <Feature: SUM(alarms.IND_DURATION)>,\n",
       " <Feature: COUNT(stoppages)>,\n",
       " <Feature: MAX(stoppages.COD_WO)>,\n",
       " <Feature: MAX(stoppages.IND_DURATION)>,\n",
       " <Feature: MAX(stoppages.IND_LOST_GEN)>,\n",
       " <Feature: MIN(stoppages.COD_WO)>,\n",
       " <Feature: MIN(stoppages.IND_DURATION)>,\n",
       " <Feature: MIN(stoppages.IND_LOST_GEN)>,\n",
       " <Feature: SUM(stoppages.COD_WO)>,\n",
       " <Feature: SUM(stoppages.IND_DURATION)>,\n",
       " <Feature: SUM(stoppages.IND_LOST_GEN)>,\n",
       " <Feature: COUNT(pidata)>,\n",
       " <Feature: MAX(pidata.val1)>,\n",
       " <Feature: MAX(pidata.val2)>,\n",
       " <Feature: MIN(pidata.val1)>,\n",
       " <Feature: MIN(pidata.val2)>,\n",
       " <Feature: SUM(pidata.val1)>,\n",
       " <Feature: SUM(pidata.val2)>,\n",
       " <Feature: COUNT(alarms WHERE DES_NAME = Alarm2)>,\n",
       " <Feature: COUNT(alarms WHERE DES_NAME = Alarm1)>,\n",
       " <Feature: SUM(alarms.IND_DURATION WHERE DES_NAME = Alarm2)>,\n",
       " <Feature: SUM(alarms.IND_DURATION WHERE DES_NAME = Alarm1)>,\n",
       " <Feature: MAX(stoppages.NUM_WORDS(DES_COMMENTS))>,\n",
       " <Feature: MAX(stoppages.NUM_WORDS(DES_DESCRIPTION))>,\n",
       " <Feature: MAX(stoppages.NUM_WORDS(DES_WO_NAME))>,\n",
       " <Feature: MIN(stoppages.NUM_WORDS(DES_COMMENTS))>,\n",
       " <Feature: MIN(stoppages.NUM_WORDS(DES_DESCRIPTION))>,\n",
       " <Feature: MIN(stoppages.NUM_WORDS(DES_WO_NAME))>,\n",
       " <Feature: SUM(stoppages.NUM_WORDS(DES_COMMENTS))>,\n",
       " <Feature: SUM(stoppages.NUM_WORDS(DES_DESCRIPTION))>,\n",
       " <Feature: SUM(stoppages.NUM_WORDS(DES_WO_NAME))>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import featuretools as ft\n",
    "\n",
    "interesting_alarms = ['Alarm1', 'Alarm2']\n",
    "pidata_es.add_interesting_values(dataframe_name='alarms', values={'DES_NAME': interesting_alarms})\n",
    "\n",
    "feature_matrix, features = ft.dfs(\n",
    "    entityset=pidata_es,\n",
    "    target_dataframe_name='turbines',\n",
    "    cutoff_time_in_index=True,\n",
    "    cutoff_time=label_times,\n",
    "    where_primitives=['count', 'sum'],\n",
    "    agg_primitives=['count', 'min', 'max', 'sum'],\n",
    "    trans_primitives=['num_words'],\n",
    "    ignore_dataframes=['notifications', 'work_orders']    \n",
    ")\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdce0acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TURBINE_PI_ID</th>\n",
       "      <th>TURBINE_LOCAL_ID</th>\n",
       "      <th>TURBINE_SAP_COD</th>\n",
       "      <th>DES_CORE_ELEMENT</th>\n",
       "      <th>SITE</th>\n",
       "      <th>DES_CORE_PLANT</th>\n",
       "      <th>COD_PLANT_SAP</th>\n",
       "      <th>PI_COLLECTOR_SITE_NAME</th>\n",
       "      <th>PI_LOCAL_SITE_NAME</th>\n",
       "      <th>COUNT(alarms)</th>\n",
       "      <th>...</th>\n",
       "      <th>MAX(stoppages.NUM_WORDS(DES_COMMENTS))</th>\n",
       "      <th>MAX(stoppages.NUM_WORDS(DES_DESCRIPTION))</th>\n",
       "      <th>MAX(stoppages.NUM_WORDS(DES_WO_NAME))</th>\n",
       "      <th>MIN(stoppages.NUM_WORDS(DES_COMMENTS))</th>\n",
       "      <th>MIN(stoppages.NUM_WORDS(DES_DESCRIPTION))</th>\n",
       "      <th>MIN(stoppages.NUM_WORDS(DES_WO_NAME))</th>\n",
       "      <th>SUM(stoppages.NUM_WORDS(DES_COMMENTS))</th>\n",
       "      <th>SUM(stoppages.NUM_WORDS(DES_DESCRIPTION))</th>\n",
       "      <th>SUM(stoppages.NUM_WORDS(DES_WO_NAME))</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COD_ELEMENT</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>TA00</td>\n",
       "      <td>A0</td>\n",
       "      <td>LOC000</td>\n",
       "      <td>T00</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>LOC</td>\n",
       "      <td>ABC</td>\n",
       "      <td>LOC0</td>\n",
       "      <td>LOC0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45801.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       TURBINE_PI_ID TURBINE_LOCAL_ID TURBINE_SAP_COD  \\\n",
       "COD_ELEMENT time                                                        \n",
       "0           2022-01-01          TA00               A0          LOC000   \n",
       "\n",
       "                       DES_CORE_ELEMENT      SITE DES_CORE_PLANT  \\\n",
       "COD_ELEMENT time                                                   \n",
       "0           2022-01-01              T00  LOCATION            LOC   \n",
       "\n",
       "                       COD_PLANT_SAP PI_COLLECTOR_SITE_NAME  \\\n",
       "COD_ELEMENT time                                              \n",
       "0           2022-01-01           ABC                   LOC0   \n",
       "\n",
       "                       PI_LOCAL_SITE_NAME  COUNT(alarms)  ...  \\\n",
       "COD_ELEMENT time                                          ...   \n",
       "0           2022-01-01               LOC0              1  ...   \n",
       "\n",
       "                        MAX(stoppages.NUM_WORDS(DES_COMMENTS))  \\\n",
       "COD_ELEMENT time                                                 \n",
       "0           2022-01-01                                     4.0   \n",
       "\n",
       "                        MAX(stoppages.NUM_WORDS(DES_DESCRIPTION))  \\\n",
       "COD_ELEMENT time                                                    \n",
       "0           2022-01-01                                        2.0   \n",
       "\n",
       "                        MAX(stoppages.NUM_WORDS(DES_WO_NAME))  \\\n",
       "COD_ELEMENT time                                                \n",
       "0           2022-01-01                                    3.0   \n",
       "\n",
       "                        MIN(stoppages.NUM_WORDS(DES_COMMENTS))  \\\n",
       "COD_ELEMENT time                                                 \n",
       "0           2022-01-01                                     4.0   \n",
       "\n",
       "                        MIN(stoppages.NUM_WORDS(DES_DESCRIPTION))  \\\n",
       "COD_ELEMENT time                                                    \n",
       "0           2022-01-01                                        2.0   \n",
       "\n",
       "                        MIN(stoppages.NUM_WORDS(DES_WO_NAME))  \\\n",
       "COD_ELEMENT time                                                \n",
       "0           2022-01-01                                    3.0   \n",
       "\n",
       "                        SUM(stoppages.NUM_WORDS(DES_COMMENTS))  \\\n",
       "COD_ELEMENT time                                                 \n",
       "0           2022-01-01                                     4.0   \n",
       "\n",
       "                        SUM(stoppages.NUM_WORDS(DES_DESCRIPTION))  \\\n",
       "COD_ELEMENT time                                                    \n",
       "0           2022-01-01                                        2.0   \n",
       "\n",
       "                        SUM(stoppages.NUM_WORDS(DES_WO_NAME))    label  \n",
       "COD_ELEMENT time                                                        \n",
       "0           2022-01-01                                    3.0  45801.0  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8eefd3",
   "metadata": {},
   "source": [
    "## 3) Feature Engineering with SigPro\n",
    "\n",
    "Process signals with [SigPro](https://github.com/sintel-dev/SigPro) for PI signals or SCADA signals.\n",
    "\n",
    "Processing signals is done by specifying the `transformations` and `aggregations` we wish to apply to the data. To look at some of the primitives readily available, we use `get_primitives` function from `SigPro`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "191a123a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sigpro.SigPro',\n",
       " 'sigpro.aggregations.amplitude.statistical.crest_factor',\n",
       " 'sigpro.aggregations.amplitude.statistical.kurtosis',\n",
       " 'sigpro.aggregations.amplitude.statistical.mean',\n",
       " 'sigpro.aggregations.amplitude.statistical.rms',\n",
       " 'sigpro.aggregations.amplitude.statistical.skew',\n",
       " 'sigpro.aggregations.amplitude.statistical.std',\n",
       " 'sigpro.aggregations.amplitude.statistical.var',\n",
       " 'sigpro.aggregations.frequency.band.band_mean',\n",
       " 'sigpro.transformations.amplitude.identity.identity',\n",
       " 'sigpro.transformations.amplitude.spectrum.power_spectrum',\n",
       " 'sigpro.transformations.frequency.band.frequency_band',\n",
       " 'sigpro.transformations.frequency.fft.fft',\n",
       " 'sigpro.transformations.frequency.fft.fft_real',\n",
       " 'sigpro.transformations.frequency_time.stft.stft',\n",
       " 'sigpro.transformations.frequency_time.stft.stft_real']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sigpro import get_primitives\n",
    "\n",
    "get_primitives()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b23aff6",
   "metadata": {},
   "source": [
    "Suppose we are interested in finding the amplitude mean for each month of readings in the signal. We first specify the `name` and respective `primitive` we want to apply for both `transformations` and `aggregations`.\n",
    "\n",
    "In this case, we are interested in an identity transformation and mean aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961af0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = [{\n",
    "    \"name\":\"mean\",\n",
    "    \"primitive\":\"sigpro.aggregations.amplitude.statistical.mean\"\n",
    "}]\n",
    "\n",
    "transformations = [{\n",
    "    \"name\":\"fft\",\n",
    "    \"primitive\":\"sigpro.transformations.amplitude.identity.identity\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a3f3a6",
   "metadata": {},
   "source": [
    "We use `process_signals` function to accomplish our goal. We pass the following:\n",
    "- `es`: the entityset we are working with.\n",
    "- `signal_dataframe_name`: the name of the dataframe whether `pidata` or `scada`.\n",
    "- `signal_column`: the name of the signal column in the dataframe.\n",
    "- `window_size`: the size of the bin we want to process the signals over, e.g. each month.\n",
    "- `replace_dataframe`: an indicator whether we want to replace the current dataframe or add it as a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea94368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarah/anaconda3/envs/Zephyr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/sarah/anaconda3/envs/Zephyr/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_index</th>\n",
       "      <th>COD_ELEMENT</th>\n",
       "      <th>time</th>\n",
       "      <th>fft.mean.mean_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>9872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _index COD_ELEMENT       time  fft.mean.mean_value\n",
       "0       0           0 2022-01-31                 9872\n",
       "1       1           0 2022-02-28                 <NA>\n",
       "2       2           0 2022-03-31                  559"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zephyr_ml.feature_engineering import process_signals\n",
    "\n",
    "process_signals(es=pidata_es, \n",
    "                signal_dataframe_name='pidata', \n",
    "                signal_column='val1', \n",
    "                transformations=transformations, \n",
    "                aggregations=aggregations,\n",
    "                window_size='1m', \n",
    "                replace_dataframe=False)\n",
    "\n",
    "pidata_es['pidata_processed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd88812a",
   "metadata": {},
   "source": [
    "Based on our original observations of `val1`, we now have `pidata_processed` with an entry for each month and the respective mean value of observations we see in that month.\n",
    "\n",
    "**Note**: in the months we don't have observations, the value becomes null."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d6fabd7bf745a21519616ebdce3b2479184204dadf576aa19f086ff78438203"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
